# source /root/autodl-tmp/LLM_RL_basic/.py_c128/bin/activate
# source /etc/network_turbo
# unset http_proxy && unset https_proxy
/root/autodl-tmp/LLM_RL_basic/.py_c128/lib/python3.12/site-packages/verl

# Github SSH
ssh-keygen -t ed25519 -C "tinpingchan@yahoo.com"
eval "$(ssh-agent -s)"
ssh-add ~/.ssh/id_ed25519
cat ~/.ssh/id_ed25519.pub
打开 GitHub → Settings → SSH and GPG keys → New SSH key → 粘贴上面的公钥 → 保存
ssh -T git@github.com

git remote set-url origin git@github.com:ChanTinPing/LLM_RL_basic.git

# 代码输出
import os, datetime
def _log(p):
    ts = datetime.datetime.now().strftime("%F %T")
    os.makedirs("/root/autodl-tmp/LLM_RL_basic/outputs", exist_ok=True)
    with open("/root/autodl-tmp/LLM_RL_basic/outputs/ppo_trace.txt","a",encoding="utf-8") as f:
        f.write(f"[{ts}] {p}\n"); f.flush(); os.fsync(f.fileno())

_log("ENTER run_ppo")

import os, datetime
def _trace(msg):
    ts = datetime.datetime.now().strftime("%F %T")
    os.makedirs("/root/autodl-tmp/LLM_RL_basic/outputs", exist_ok=True)
    with open("/root/autodl-tmp/LLM_RL_basic/outputs/model_load_trace.txt","a",encoding="utf-8") as f:
        f.write(f"[{ts}] {msg}\n"); f.flush(); os.fsync(f.fileno())
_trace(f"_load_hf_model: is_value_model={is_value_model}, local_cache_path={local_cache_path}")

# python 安装
pip install torch --index-url https://download.pytorch.org/whl/cu128
pip install "verl[trl, vllm]"
pip install flash-attn --no-build-isolation
pip install bitsandbytes
pip install wandb
